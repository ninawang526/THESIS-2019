{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import THESIS2019.to_lexicon as lex\n",
    "from base_words import *\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "import gensim\n",
    "from gensim.models.wrappers import DtmModel\n",
    "from gensim.models import LdaSeqModel\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "import os, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered 275 articles from 2012\n",
      "Gathered 5971 articles from 2016\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/ninawang/Thesis/remote/THESIS2019/NYT-OPINION2012-2013-processed/\"\n",
    "\n",
    "start = datetime.datetime(2012, 6, 1)\n",
    "end = datetime.datetime(2013, 7, 1)\n",
    "\n",
    "articles2012 = lex.get_articles_from_filepath(path,start,end)\n",
    "\n",
    "path = \"/Users/ninawang/Thesis/remote/THESIS2019/NYT-OPINION2016-2017-processed/\"\n",
    "\n",
    "start = datetime.datetime(2016, 6, 1)\n",
    "end = datetime.datetime(2017, 7, 1)\n",
    "\n",
    "articles2016 = lex.get_articles_from_filepath(path,start,end)\n",
    "\n",
    "print(\"Gathered %d articles from 2012\" %len(articles2012))\n",
    "print(\"Gathered %d articles from 2016\" %len(articles2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem2012, rep2012 = lex.get_collocations(articles2012, LEFT_WORDS, RIGHT_WORDS)\n",
    "dem2016, rep2016 = lex.get_collocations(articles2016, LEFT_WORDS, RIGHT_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ! DUMP ! ######\n",
    "# with open(\"2016-collocations-dem.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(dem2016, f)\n",
    "# with open(\"2016-collocations-rep.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(rep2016, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_and_timeslices(col):\n",
    "    total = [d for d in col if d[0] is not None]\n",
    "    docs = [d[1] for d in total]\n",
    "    timeslices = [d[0].year for d in total]\n",
    "    return docs, timeslices\n",
    "\n",
    "dems_docs_2012, dems_timeslices_2012 = get_doc_and_timeslices(dem2012)\n",
    "dems_docs_2016, dems_timeslices_2016 = get_doc_and_timeslices(dem2016)\n",
    "combined = dems_docs_2012 + dems_docs_2016\n",
    "\n",
    "dct = Dictionary(combined)\n",
    "docs = []\n",
    "for text in combined:\n",
    "    docs.append(dct.doc2bow(text))\n",
    "    \n",
    "my_corpus = docs\n",
    "my_timeslices = [len(dems_docs_2012),len(dems_docs_2016)]\n",
    "exe = \"../dtm-darwin64\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "1921\n"
     ]
    }
   ],
   "source": [
    "print(len(dems_docs_2012))\n",
    "print(len(dems_docs_2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DtmModel(exe, my_corpus, my_timeslices, num_topics=15, id2word=dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ! DUMP ! ######\n",
    "# with open(\"sample-dtm.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.086*right + 0.072*gun + 0.057*abort + 0.050*justic + 0.048*issu',\n",
       " '0.025*women + 0.012*white + 0.009*men + 0.008*work + 0.007*say',\n",
       " '0.038*immigr + 0.028*union + 0.021*european + 0.017*europ + 0.016*right',\n",
       " '0.023*vote + 0.016*voter + 0.014*elect + 0.013*state + 0.010*parti',\n",
       " '0.223*russia + 0.133*lie + 0.119*order + 0.119*putin + 0.059*hack',\n",
       " '0.037*presid + 0.016*black + 0.011*year + 0.010*first + 0.009*nation',\n",
       " '0.204*sign + 0.136*opinion + 0.120*newslett + 0.045*warren + 0.036*articl',\n",
       " '0.034*parti + 0.024*polit + 0.019*social + 0.011*cultur + 0.010*peopl',\n",
       " '0.013*get + 0.011*say + 0.008*make + 0.008*peopl + 0.008*time',\n",
       " '0.012*presid + 0.007*year + 0.007*care + 0.007*administr + 0.007*health',\n",
       " '0.166*continu + 0.157*read + 0.148*main + 0.146*stori + 0.144*advertis',\n",
       " '0.017*email + 0.011*investig + 0.010*presid + 0.009*report + 0.009*comey',\n",
       " '0.018*state + 0.016*presid + 0.014*unit + 0.011*american + 0.011*administr',\n",
       " '0.064*york + 0.063*new + 0.061*time + 0.047*view + 0.046*later',\n",
       " '0.091*muslim + 0.058*news + 0.051*gay + 0.032*violenc + 0.032*word',\n",
       " '0.087*right + 0.072*gun + 0.057*abort + 0.051*justic + 0.049*issu',\n",
       " '0.025*women + 0.012*white + 0.009*men + 0.008*work + 0.008*say',\n",
       " '0.038*immigr + 0.028*union + 0.021*european + 0.017*europ + 0.016*right',\n",
       " '0.024*vote + 0.016*voter + 0.015*elect + 0.013*state + 0.010*parti',\n",
       " '0.224*russia + 0.133*lie + 0.120*putin + 0.120*order + 0.059*hack',\n",
       " '0.038*presid + 0.016*black + 0.011*year + 0.010*first + 0.009*nation',\n",
       " '0.206*sign + 0.136*opinion + 0.121*newslett + 0.045*warren + 0.036*articl',\n",
       " '0.035*parti + 0.024*polit + 0.020*social + 0.011*cultur + 0.010*peopl',\n",
       " '0.013*get + 0.012*say + 0.008*make + 0.008*peopl + 0.008*time',\n",
       " '0.012*presid + 0.008*year + 0.007*care + 0.007*administr + 0.007*health',\n",
       " '0.167*continu + 0.158*read + 0.149*main + 0.147*stori + 0.145*advertis',\n",
       " '0.017*email + 0.011*investig + 0.010*presid + 0.009*report + 0.009*comey',\n",
       " '0.018*state + 0.016*presid + 0.014*unit + 0.011*american + 0.011*administr',\n",
       " '0.065*york + 0.064*new + 0.061*time + 0.048*view + 0.046*later',\n",
       " '0.093*muslim + 0.058*news + 0.050*gay + 0.032*violenc + 0.032*word']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.print_topics(num_topics=-1,num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/gensim/models/ldaseqmodel.py:293: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  convergence = np.fabs((bound - old_bound) / old_bound)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "ldaseq = LdaSeqModel(corpus=my_corpus, id2word=dct, time_slice=my_timeslices, num_topics=15)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
